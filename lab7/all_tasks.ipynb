{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73df418-db47-4d44-a84f-21debeee86f7",
   "metadata": {},
   "source": [
    "### Задание на ПР-7:\n",
    "В приложенном датасете приведены данные о реальных больных сердечно-сосудистыми заболеваниями. Последняя компонента в каждом экземпляре - бинарная метка (0 - нет болезни, 1 - есть болезнь). Ваша задача - построить классификатор, который на данных нового пациента предскажет наличие у него болезни. Затем нужно вычислить метрики качества вашего классификатора. \n",
    "1. Сделайте препроцессинг.\n",
    "2. Разделите данные на обучающие и тестовые (70/30), причем проследите чтобы пропорции 0 и 1 в них были примерно одинаковыми.\n",
    "3. Напишите функцию, которая вычислит коэффициенты логистической регрессии на обучающей выборке.\n",
    "4. Напишите функцию, которая предскажет метку на тестовом экземпляре данных, пользуясь вычисленными коэффициентами логистической регрессии (ЛР).\n",
    "5. Выберите из датасета такие экземпляры, на которых логистическая регрессия дает нестабильные предсказания. Таких экземпляров должно быть не менее 20% от всего датасета. Отметьте их третьим типом метки (например, -1, или 2 - как вам нравится больше).\n",
    "6. Постройте классификацию (выполните пп. 3 и 4) методом ближайших соседей (БС). \n",
    "7. Измерьте качество классификации для ЛР и БС по метрикам Precision, Recall, F1 (для бинарной классификации) и Accuracy (для тернарной классификации). \n",
    "8. Интерпретируйте результаты - сделайте выводы о качестве классификации, проведенной на основе разных методов и с разным числом классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20b499-1a78-44ee-9b8f-21aba4034153",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 1: ПРЕПРОЦЕССИНГ ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16e8b667-8ab3-4ce7-b732-0e5104ace008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 строк исходных данных:\n",
      "Пациент 1: ['40', 'M', 'ATA', '140', '289', '0', 'Normal', '172', 'N', '0', 'Up', '0']\n",
      "Пациент 2: ['49', 'F', 'NAP', '160', '180', '0', 'Normal', '156', 'N', '1', 'Flat', '1']\n",
      "Пациент 3: ['37', 'M', 'ATA', '130', '283', '0', 'ST', '98', 'N', '0', 'Up', '0']\n",
      "Пациент 4: ['48', 'F', 'ASY', '138', '214', '0', 'Normal', '108', 'Y', '1.5', 'Flat', '1']\n",
      "Пациент 5: ['54', 'M', 'NAP', '150', '195', '0', 'Normal', '122', 'N', '0', 'Up', '0']\n",
      "\n",
      "Загружено 918 пациентов\n",
      "Количество признаков: 11\n"
     ]
    }
   ],
   "source": [
    "# 1. Сделайте препроцессинг.\n",
    "# Импорт библиотек\n",
    "import math  # для математических операций\n",
    "import random  # для случайных чисел и перемешивания\n",
    "import csv  # для работы с CSV файлами\n",
    "\n",
    "def load_heart_data(filename):\n",
    "    \"\"\"Загружает данные о сердечных заболеваниях из CSV файла\"\"\"\n",
    "    dataset = []  # список для хранения данных\n",
    "    with open(filename, 'r') as file:  # открываем файл для чтения\n",
    "        csv_reader = csv.reader(file)  # создаем CSV reader\n",
    "        headers = next(csv_reader)  # читаем и сохраняем заголовки\n",
    "        for row in csv_reader:  # читаем каждую строку\n",
    "            dataset.append(row)  # добавляем строку в датасет\n",
    "    return dataset  # возвращаем загруженные данные\n",
    "\n",
    "def preprocess_heart_data(raw_data):\n",
    "    \"\"\"Преобразует категориальные признаки в числовые и масштабирует данные\"\"\"\n",
    "    # Словари для преобразования категориальных признаков\n",
    "    sex_map = {'M': 1, 'F': 0}  # мужской=1, женский=0\n",
    "    chest_pain_map = {'ATA': 0, 'NAP': 1, 'ASY': 2, 'TA': 3}  # типы боли в груди\n",
    "    ecg_map = {'Normal': 0, 'ST': 1, 'LVH': 2}  # типы ЭКГ\n",
    "    angina_map = {'N': 0, 'Y': 1}  # наличие стенокардии\n",
    "    slope_map = {'Up': 0, 'Flat': 1, 'Down': 2}  # наклон ST сегмента\n",
    "    \n",
    "    processed_data = []  # список для обработанных данных\n",
    "    \n",
    "    for patient in raw_data:  # обрабатываем каждого пациента\n",
    "        processed_patient = []  # список для обработанного пациента\n",
    "        \n",
    "        # Преобразуем каждый признак в числовой формат\n",
    "        processed_patient.append(int(patient[0]))  # возраст -> целое число\n",
    "        processed_patient.append(sex_map[patient[1]])  # пол по словарю\n",
    "        processed_patient.append(chest_pain_map[patient[2]])  # тип боли\n",
    "        processed_patient.append(int(patient[3]))  # давление -> целое число\n",
    "        processed_patient.append(int(patient[4]))  # холестерин -> целое число\n",
    "        processed_patient.append(int(patient[5]))  # уровень сахара -> целое число\n",
    "        processed_patient.append(ecg_map[patient[6]])  # ЭКГ по словарю\n",
    "        processed_patient.append(int(patient[7]))  # пульс -> целое число\n",
    "        processed_patient.append(angina_map[patient[8]])  # стенокардия по словарю\n",
    "        processed_patient.append(float(patient[9]))  # ST депрессия -> дробное число\n",
    "        processed_patient.append(slope_map[patient[10]])  # наклон ST по словарю\n",
    "        processed_patient.append(int(patient[11]))  # метка болезни -> целое число\n",
    "        \n",
    "        processed_data.append(processed_patient)  # добавляем обработанного пациента\n",
    "    \n",
    "    # Масштабируем признаки (кроме метки)\n",
    "    # Стандартизация: x_std = (x - mean) / std\n",
    "    num_features = len(processed_data[0]) - 1  # количество признаков (без метки)\n",
    "    for feature_idx in range(num_features):  # для каждого признака\n",
    "        feature_values = []  # создаем пустой список для значений признака\n",
    "        for patient in processed_data:  # для каждого пациента в обработанных данных\n",
    "            value = patient[feature_idx]  # берем значение признака по индексу\n",
    "            feature_values.append(value)  # добавляем значение в список\n",
    "        \n",
    "        # Вычисляем среднее и стандартное отклонение\n",
    "        mean_val = sum(feature_values) / len(feature_values)  # среднее значение\n",
    "        \n",
    "        # Вычисляем сумму квадратов отклонений\n",
    "        sum_squared_diff = 0.0\n",
    "        for x in feature_values:\n",
    "            squared_diff = (x - mean_val) ** 2 # (x - μ)²\n",
    "            sum_squared_diff += squared_diff\n",
    "\n",
    "        # Вычисляем стандартное отклонение\n",
    "        variance = sum_squared_diff / len(feature_values)  # дисперсия\n",
    "        std_val = variance ** 0.5  # квадратный корень = стандартное отклонение\n",
    "        \n",
    "        if std_val > 0:  # если значения не постоянны\n",
    "            for i in range(len(processed_data)):  # масштабируем каждый элемент\n",
    "                processed_data[i][feature_idx] = (processed_data[i][feature_idx] - mean_val) / std_val\n",
    "    \n",
    "    return processed_data  # возвращаем обработанные данные\n",
    "\n",
    "# Загружаем и обрабатываем данные\n",
    "raw_heart_data = load_heart_data('heart.csv')  # загружаем исходные данные\n",
    "print(\"Первые 5 строк исходных данных:\")\n",
    "for i in range(min(5, len(raw_heart_data))):  # выводим первые 5 строк\n",
    "    print(f\"Пациент {i+1}: {raw_heart_data[i]}\")\n",
    "\n",
    "processed_heart_data = preprocess_heart_data(raw_heart_data)  # обрабатываем данные\n",
    "print(f\"\\nЗагружено {len(processed_heart_data)} пациентов\")  # выводим количество пациентов\n",
    "print(f\"Количество признаков: {len(processed_heart_data[0]) - 1}\")  # выводим количество признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa485b36-c93d-4546-969a-ff574f2026b3",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 2: РАЗДЕЛЕНИЕ ДАННЫХ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30830393-96d5-49c8-986f-c292f05d9392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 643 пациентов\n",
      "Тестовая выборка: 275 пациентов\n",
      "Распределение классов в обучении: 0=287, 1=356\n"
     ]
    }
   ],
   "source": [
    "# 2. Разделите данные на обучающие и тестовые (70/30), причем проследите чтобы пропорции 0 и 1 в них были примерно одинаковыми.\n",
    "def split_data_stratified(dataset, test_ratio=0.3, label_index=-1):\n",
    "    \"\"\"Разделяет данные на обучающую и тестовую выборки с сохранением пропорций классов\"\"\"\n",
    "    # Разделяем данные по классам\n",
    "    class_0 = []  # пациенты без болезни\n",
    "    class_1 = []  # пациенты с болезнью\n",
    "    \n",
    "    for patient in dataset:  # распределяем пациентов по классам\n",
    "        if patient[label_index] == 0:  # если пациент без болезни\n",
    "            class_0.append(patient)  # добавляем в класс 0\n",
    "        else:  # если пациент с болезнью\n",
    "            class_1.append(patient)  # добавляем в класс 1\n",
    "    \n",
    "    # Перемешиваем данные в каждом классе\n",
    "    random.shuffle(class_0)  # перемешиваем класс 0\n",
    "    random.shuffle(class_1)  # перемешиваем класс 1\n",
    "    \n",
    "    # Вычисляем размер тестовой выборки для каждого класса\n",
    "    test_size_0 = int(len(class_0) * test_ratio)  # размер теста для класса 0 , 30% от class_0\n",
    "    test_size_1 = int(len(class_1) * test_ratio)  # размер теста для класса 1 , 30% от class_1\n",
    "    \n",
    "    # Формируем тестовую выборку\n",
    "    test_data = class_0[:test_size_0] + class_1[:test_size_1]  # берем первые элементы для теста\n",
    "    \n",
    "    # Формируем обучающую выборку\n",
    "    train_data = class_0[test_size_0:] + class_1[test_size_1:]  # остальные для обучения\n",
    "    \n",
    "    # Перемешиваем итоговые выборки\n",
    "    random.shuffle(train_data)  # перемешиваем обучающую выборку\n",
    "    random.shuffle(test_data)  # перемешиваем тестовую выборку\n",
    "    \n",
    "    # Разделяем на признаки и метки\n",
    "    X_train = [] # признаки\n",
    "    y_train = [] # метки\n",
    "    for patient in train_data:  # для каждого пациента в обучающей выборке\n",
    "        X_train.append(patient[:-1])  # добавляем признаки (все кроме последнего)\n",
    "        y_train.append(patient[-1])   # добавляем метку (последний элемент)\n",
    "    \n",
    "    X_test = [] # признаки\n",
    "    y_test = [] # метки\n",
    "    for patient in test_data:  # для каждого пациента в тестовой выборке\n",
    "        X_test.append(patient[:-1])  # добавляем признаки (все кроме последнего)\n",
    "        y_test.append(patient[-1])   # добавляем метку (последний элемент)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test  # возвращаем разделенные данные\n",
    "\n",
    "# Разделяем данные\n",
    "X_train, X_test, y_train, y_test = split_data_stratified(processed_heart_data)  # разделяем данные\n",
    "\n",
    "print(f\"Обучающая выборка: {len(X_train)} пациентов\")  # выводим размер обучающей выборки\n",
    "print(f\"Тестовая выборка: {len(X_test)} пациентов\")  # выводим размер тестовой выборки\n",
    "\n",
    "# Подсчитываем распределение классов в обучающей выборке\n",
    "class_count_train = [0, 0]  # счетчики для классов 0 и 1\n",
    "for label in y_train:  # проходим по всем меткам обучения\n",
    "    class_count_train[label] += 1  # увеличиваем соответствующий счетчик\n",
    "\n",
    "print(f\"Распределение классов в обучении: 0={class_count_train[0]}, 1={class_count_train[1]}\")  # выводим распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc84eb5-978b-4eb2-ae84-9ff08e95c414",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 3: РЕАЛИЗАЦИЯ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ И ОБУЧЕНИЕ МОДЕЛИ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05746b68-292d-4f68-9361-dbe014205810",
   "metadata": {},
   "source": [
    "**Для логистической регрессии градиент вычисляется по формуле:**\n",
    "\n",
    "∂L/∂α = (ŷ - y) - градиент для свободного члена\n",
    "\n",
    "∂L/∂βᵢ = (ŷ - y) × xᵢ - градиент для коэффициента признака i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc88c970-748d-442d-8277-8cebfb60bdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение логистической регрессии...\n",
      "Эпоха 100, Средние потери: 0.3675\n",
      "Эпоха 200, Средние потери: 0.3624\n",
      "Эпоха 300, Средние потери: 0.3616\n",
      "Эпоха 400, Средние потери: 0.3615\n",
      "Эпоха 500, Средние потери: 0.3615\n",
      "Эпоха 600, Средние потери: 0.3614\n",
      "Эпоха 700, Средние потери: 0.3614\n",
      "Эпоха 800, Средние потери: 0.3614\n",
      "Эпоха 900, Средние потери: 0.3614\n",
      "Эпоха 1000, Средние потери: 0.3614\n",
      "Обучение завершено!\n",
      "Обученные веса: ['0.4390', '0.1179', '0.4583', '0.7494', '0.0411', '-0.2434', '0.4525', '0.0700', '-0.3227', '0.5986', '0.3429', '0.9204']\n"
     ]
    }
   ],
   "source": [
    "def sigmoid_function(x):\n",
    "    \"\"\"Сигмоидная функция с защитой от переполнения\"\"\"\n",
    "    if x < -700:  # для очень маленьких значений, x стремится в -беск\n",
    "        return 0.0  # возвращаем 0\n",
    "    elif x > 700:  # для очень больших значений, x стремится в +беск\n",
    "        return 1.0  # возвращаем 1\n",
    "    return 1.0 / (1.0 + math.exp(-x))  # вычисляем сигмоиду\n",
    "\n",
    "def compute_logistic_prediction(features, weights):\n",
    "    \"\"\"Вычисляет предсказание логистической регрессии\"\"\"\n",
    "    # Промежуточные вычисления z = α + β₁x₁ + β₂x₂ + ... + βₙxₙ\n",
    "    z = weights[0]  # начинаем со свободного члена α\n",
    "    for i in range(len(features)):  # для каждого признака\n",
    "        z += weights[i + 1] * features[i]  # добавляем взвешенный признак, то есть β₁x₁ + β₂x₂ + ...\n",
    "    return sigmoid_function(z)  # возвращаем ŷ (предсказание модели) через сигмоиду\n",
    "\n",
    "def compute_log_loss(features, true_label, weights):\n",
    "    \"\"\"Вычисляет логарифмическую потерю для одного наблюдения\"\"\"\n",
    "    prediction = compute_logistic_prediction(features, weights)  # получаем предсказание, вероятность того, что пациент болен\n",
    "    epsilon = 1e-15  # маленькое число для избежания log(0)\n",
    "    prediction = max(min(prediction, 1 - epsilon), epsilon)  # ограничиваем предсказание\n",
    "\n",
    "    # Минимизируем ошибку, поэтому минус\n",
    "    if true_label == 1:  # если истинная метка = 1 (пациент болен)\n",
    "        return -math.log(prediction)  # -log(ŷ)\n",
    "    else:  # если истинная метка = 0 (паицент здоров)\n",
    "        return -math.log(1 - prediction)  # -log(1-ŷ)\n",
    "\n",
    "def compute_gradient(features, true_label, weights):\n",
    "    \"\"\"Вычисляет градиент для одного наблюдения\"\"\"\n",
    "    prediction = compute_logistic_prediction(features, weights)  # получаем предсказание\n",
    "    error = prediction - true_label  # вычисляем ошибку\n",
    "    \n",
    "    gradient = [error]  # градиент для свободного члена α\n",
    "    for feature in features:  # для каждого признака\n",
    "        gradient.append(error * feature)  # градиент для веса признака\n",
    "    \n",
    "    return gradient  # возвращаем градиент\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, learning_rate=0.01, iters=1000):\n",
    "    \"\"\"Обучает логистическую регрессию с помощью градиентного спуска\"\"\"\n",
    "    num_features = len(X_train[0])  # количество признаков\n",
    "    weights = [0.0] * (num_features + 1)  # инициализируем веса (включая свободный член, поэтому +1)\n",
    "    \n",
    "    for iter in range(iters):  # для каждой итерации\n",
    "        total_gradient = [0.0] * len(weights)  # инициализируем список для накопления градиентов\n",
    "        \n",
    "        for i in range(len(X_train)):  # для каждого обучающего примера (то есть пациента)\n",
    "            sample_gradient = compute_gradient(X_train[i], y_train[i], weights)  # вычисляем градиент (для одного пациента)\n",
    "            for j in range(len(weights)):  # для каждого веса\n",
    "                total_gradient[j] += sample_gradient[j]  # суммируем градиенты\n",
    "        \n",
    "        # Усредняем градиент и обновляем веса\n",
    "        for j in range(len(weights)):  # для каждого веса\n",
    "            weights[j] -= learning_rate * (total_gradient[j] / len(X_train))  # градиентный спуск\n",
    "        \n",
    "        # Выводим прогресс каждые 100 итераций\n",
    "        if (iter + 1) % 100 == 0:  # каждые 100 итераций\n",
    "            total_loss = 0.0  # инициализируем суммарные потери\n",
    "            for i in range(len(X_train)):  # для каждого обучающего примера\n",
    "                total_loss += compute_log_loss(X_train[i], y_train[i], weights)  # вычисляем потери\n",
    "            avg_loss = total_loss / len(X_train)  # усредняем потери\n",
    "            print(f\"Эпоха {iter + 1}, Средние потери: {avg_loss:.4f}\")  # выводим прогресс\n",
    "    \n",
    "    return weights  # возвращаем обученные веса\n",
    "\n",
    "print(\"Начинаем обучение логистической регрессии...\")  # сообщение о начале обучения\n",
    "lr_weights = train_logistic_regression(X_train, y_train, learning_rate=0.1, iters=1000)  # обучаем модель\n",
    "print(\"Обучение завершено!\")  # сообщение о завершении обучения\n",
    "print(f\"Обученные веса: {[f'{w:.4f}' for w in lr_weights]}\")  # выводим обученные веса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d15085-c96d-4e0a-9adf-442cabf76ebc",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 4: ПРЕДСКАЗАНИЯ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f48a0a76-b16a-4858-85d3-66af2beead6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания на тестовой выборке:\n",
      "Пример 1: Истинная метка=1, Предсказание=1, Вероятность=0.9629\n",
      "Пример 2: Истинная метка=1, Предсказание=1, Вероятность=0.5359\n",
      "Пример 3: Истинная метка=0, Предсказание=1, Вероятность=0.9796\n",
      "Пример 4: Истинная метка=1, Предсказание=1, Вероятность=0.6077\n",
      "Пример 5: Истинная метка=1, Предсказание=1, Вероятность=0.9342\n",
      "\n",
      "Точность логистической регрессии: 0.8509 (234/275)\n",
      "Матрица ошибок: TP=138, FP=27, TN=96, FN=14\n"
     ]
    }
   ],
   "source": [
    "# 4. Напишите функцию, которая предскажет метку на тестовом экземпляре данных\n",
    "def predict_logistic_regression(features, weights, threshold=0.5):\n",
    "    \"\"\"Предсказывает метку класса с помощью логистической регрессии\"\"\"\n",
    "    probability = compute_logistic_prediction(features, weights)  # вычисляем вероятность P(y=1|x)\n",
    "    if probability >= threshold:  # если вероятность >= порога (0.5 как в методичке)\n",
    "        return 1  # предсказываем класс 1\n",
    "    else:\n",
    "        return 0  # предсказываем класс 0\n",
    "\n",
    "# Предсказания на тестовой выборке \n",
    "print(\"Предсказания на тестовой выборке:\")\n",
    "test_predictions_lr = []  # список для предсказаний\n",
    "test_probabilities_lr = []  # список для вероятностей\n",
    "\n",
    "for i in range(len(X_test)):  # для каждого тестового примера\n",
    "    features = X_test[i]  # признаки тестового примера\n",
    "    true_label = y_test[i]  # истинная метка\n",
    "    \n",
    "    probability = compute_logistic_prediction(features, lr_weights)  # вычисляем вероятность\n",
    "    predicted_label = predict_logistic_regression(features, lr_weights)  # предсказываем метку\n",
    "    \n",
    "    test_probabilities_lr.append(probability)  # сохраняем вероятность\n",
    "    test_predictions_lr.append(predicted_label)  # сохраняем предсказание\n",
    "    \n",
    "    if i < 5:  # выводим первые 5 примеров для демонстрации\n",
    "        print(f\"Пример {i+1}: Истинная метка={true_label}, Предсказание={predicted_label}, Вероятность={probability:.4f}\")\n",
    "\n",
    "# Подсчет точности \n",
    "correct_predictions = 0  # счетчик правильных предсказаний\n",
    "true_positives = 0  # истинные положительные (TP)\n",
    "false_positives = 0  # ложные положительные (FP)\n",
    "true_negatives = 0  # истинные отрицательные (TN)  \n",
    "false_negatives = 0  # ложные отрицательные (FN)\n",
    "\n",
    "for i in range(len(y_test)):  # для всех тестовых примеров\n",
    "    true_label = y_test[i]  # истинная метка\n",
    "    predicted_label = test_predictions_lr[i]  # предсказанная метка\n",
    "    \n",
    "    if true_label == 1 and predicted_label == 1:  # TP\n",
    "        true_positives += 1\n",
    "        correct_predictions += 1\n",
    "    elif true_label == 1 and predicted_label == 0:  # FN\n",
    "        false_negatives += 1\n",
    "    elif true_label == 0 and predicted_label == 1:  # FP\n",
    "        false_positives += 1\n",
    "    elif true_label == 0 and predicted_label == 0:  # TN\n",
    "        true_negatives += 1\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(y_test)  # вычисляем точность\n",
    "print(f\"\\nТочность логистической регрессии: {accuracy:.4f} ({correct_predictions}/{len(y_test)})\")\n",
    "print(f\"Матрица ошибок: TP={true_positives}, FP={false_positives}, TN={true_negatives}, FN={false_negatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379e038-cbb3-4a5e-bbfe-2edcae283eb5",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 5: ВЫДЕЛЕНИЕ НЕСТАБИЛЬНЫХ СЛУЧАЕВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b417166b-0e21-4c48-8937-2f76d5802dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов:\n",
      "Класс 0: 216\n",
      "Класс 1: 497\n",
      "Класс 2: 205\n",
      "Нестабильных: 205/918 (22.3%)\n",
      "\n",
      "Данные для тернарной классификации подготовлены:\n",
      "Всего пациентов: 918\n",
      "Признаков на пациента: 11\n"
     ]
    }
   ],
   "source": [
    "# 5. Выделение нестабильных предсказаний\n",
    "import copy  # для создания копий данных\n",
    "\n",
    "# Создаем объединенный датасет \n",
    "dataset_with_labels = []  # список для данных с признаками и метками\n",
    "for i in range(len(X_train)):  # проходим по всем обучающим примерам\n",
    "    patient = X_train[i] + [y_train[i]]  # объединяем признаки и метку в один список\n",
    "    dataset_with_labels.append(patient)  # добавляем пациента в общий датасет\n",
    "for i in range(len(X_test)):  # проходим по всем тестовым примерам\n",
    "    patient = X_test[i] + [y_test[i]]    # объединяем признаки и метку в один список  \n",
    "    dataset_with_labels.append(patient)  # добавляем пациента в общий датасет\n",
    "\n",
    "# Создаем копию данных для модификации, чтобы не испортить оригинал\n",
    "dataset_copy = copy.deepcopy(dataset_with_labels)\n",
    "\n",
    "# Порог для нестабильных предсказаний\n",
    "border = 0.15  # если предсказание отличается от истины на этот порог - считаем нестабильным\n",
    "\n",
    "# Помечаем нестабильные предсказания\n",
    "for i in range(len(dataset_copy)):  # проходим по всем пациентам\n",
    "    features = dataset_copy[i][:-1]  # берем все признаки (все кроме последнего элемента)\n",
    "    true_label = dataset_copy[i][-1] # последний элемент - истинная метка класса\n",
    "    \n",
    "    prediction = compute_logistic_prediction(features, lr_weights)  # получаем предсказание модели\n",
    "    \n",
    "    if true_label == 0 and prediction >= border:  # если пациент здоров, но модель предсказывает болезнь\n",
    "        dataset_copy[i][-1] = 2  # помечаем как нестабильный (класс 2)\n",
    "    elif true_label == 1 and prediction < border:  # если пациент болен, но модель предсказывает здоровье\n",
    "        dataset_copy[i][-1] = 2  # помечаем как нестабильный (класс 2)\n",
    "\n",
    "# Подсчет и вывод результатов\n",
    "class_count = [0, 0, 0] \n",
    "for patient in dataset_copy:  # проходим по всем пациентам\n",
    "    class_count[patient[-1]] += 1  # увеличиваем счетчик соответствующего класса\n",
    "\n",
    "print(\"Распределение классов:\")\n",
    "print(f\"Класс 0: {class_count[0]}\")  \n",
    "print(f\"Класс 1: {class_count[1]}\") \n",
    "print(f\"Класс 2: {class_count[2]}\")  \n",
    "print(f\"Нестабильных: {class_count[2]}/{len(dataset_copy)} ({(class_count[2]/len(dataset_copy))*100:.1f}%)\")  # процент нестабильных\n",
    "\n",
    "# СОЗДАЕМ ПЕРЕМЕННЫЕ ДЛЯ ТЕРНАРНОЙ КЛАССИФИКАЦИИ\n",
    "X_ternary = []  # список для признаков (все классы 0,1,2)\n",
    "y_ternary = []  # список для меток (0,1,2)\n",
    "\n",
    "for patient in dataset_copy:\n",
    "    features = patient[:-1]  # все кроме последнего - признаки\n",
    "    label = patient[-1]      # последний - метка класса\n",
    "    X_ternary.append(features)\n",
    "    y_ternary.append(label)\n",
    "\n",
    "print(f\"\\nДанные для тернарной классификации подготовлены:\")\n",
    "print(f\"Всего пациентов: {len(X_ternary)}\")\n",
    "print(f\"Признаков на пациента: {len(X_ternary[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3bc4b0-36cd-45ff-a91c-399caf0943eb",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 6: РЕАЛИЗАЦИЯ МЕТОДА БЛИЖАЙШИХ СОСЕДЕЙ\n",
    "\n",
    "**Метод k ближайших соседей подразумевает такую процедуру определения метки:**\n",
    "1. Найти k экземпляров данных, ближайших к пробному вектору\n",
    "2. Определить какая метка наиболее распространена среди этих k векторов данных\n",
    "3. Присвоить эту метку пробному вектору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8344646-0616-4c32-ab30-62b5a2cdee0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка данных для KNN...\n",
      "Подготовлено 643 размеченных точек для KNN\n",
      "\n",
      "Подбор оптимального k для KNN:\n",
      "k=1: Точность = 0.7900 (79/100)\n",
      "k=2: Точность = 0.7900 (79/100)\n",
      "k=3: Точность = 0.8400 (84/100)\n",
      "k=4: Точность = 0.8400 (84/100)\n",
      "k=5: Точность = 0.8300 (83/100)\n",
      "k=6: Точность = 0.8300 (83/100)\n",
      "k=7: Точность = 0.8300 (83/100)\n",
      "\n",
      "Оптимальное k: 3 с точностью 0.8400\n",
      "Делаем предсказания KNN на тестовой выборке...\n",
      "Предсказания KNN завершены!\n"
     ]
    }
   ],
   "source": [
    "# 6. Постройте классификацию методом ближайших соседей (БС)\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"Вычисляет евклидово расстояние между двумя точками\"\"\"\n",
    "    # Формула: √(Σ(xᵢ - yᵢ)²) \n",
    "    squared_distance = 0.0  # сумма квадратов разностей\n",
    "    for i in range(len(point1)):  # для каждой координаты\n",
    "        squared_distance += (point1[i] - point2[i]) ** 2  # квадрат разности\n",
    "    return math.sqrt(squared_distance)  # квадратный корень из суммы\n",
    "\n",
    "def majority_vote(labels):\n",
    "    \"\"\"Голосование большинством с разрешением ничьих\"\"\"\n",
    "    # Подсчитываем голоса вручную\n",
    "    vote_counts = {}  # словарь для подсчета голосов\n",
    "    for label in labels:  # для каждой метки\n",
    "        if label in vote_counts:  # если метка уже есть в словаре\n",
    "            vote_counts[label] += 1  # увеличиваем счетчик\n",
    "        else:  # если метка новая\n",
    "            vote_counts[label] = 1  # инициализируем счетчик\n",
    "    \n",
    "    # Находим победителя\n",
    "    winner = None  # победитель\n",
    "    winner_count = -1  # максимальное количество голосов\n",
    "    for label, count in vote_counts.items():  # для каждой пары (метка, количество)\n",
    "        if count > winner_count:  # если нашли больше голосов\n",
    "            winner = label  # обновляем победителя\n",
    "            winner_count = count  # обновляем максимальное количество\n",
    "    \n",
    "    # Проверяем ничью \n",
    "    num_winners = 0  # количество победителей\n",
    "    for count in vote_counts.values():  # для каждого количества голосов, возвращает значения словаря в count\n",
    "        if count == winner_count:  # если равно максимальному количеству голосов\n",
    "            num_winners += 1  # увеличиваем счетчик победителей\n",
    "    \n",
    "    if num_winners == 1:  # если один победитель\n",
    "        return winner  # возвращаем победителя\n",
    "    else:  # если ничья\n",
    "        return majority_vote(labels[:-1])  # рекурсивно вызываем без последнего элемента\n",
    "\n",
    "def knn_classify(k, labeled_points, new_point):\n",
    "    \"\"\"Классификатор k ближайших соседей\"\"\"\n",
    "    # Сортируем по расстоянию\n",
    "    by_distance = []  # список кортежей для хранения (точка, метка, расстояние)\n",
    "    for point, label in labeled_points:  # для каждой размеченной точки\n",
    "        dist = euclidean_distance(point, new_point)  # вычисляем расстояние\n",
    "        by_distance.append((point, label, dist))  # добавляем в список\n",
    "    \n",
    "    # Сортируем по расстоянию (от ближайшего к дальнему)\n",
    "    for i in range(len(by_distance)): # проходим по всем элементам списка, i - текущая позиция, до которой уже отсортировано\n",
    "        for j in range(i + 1, len(by_distance)): # начинаем со следующего элемента после i и идем до конца\n",
    "            if by_distance[i][2] > by_distance[j][2]:  # если расстояние больше, меняем местами\n",
    "                by_distance[i], by_distance[j] = by_distance[j], by_distance[i]\n",
    "\n",
    "    # Берем k ближайших меток\n",
    "    k_nearest_labels = []  # создаем пустой список для меток\n",
    "    for i in range(k):  # проходим по первым k элементам\n",
    "        label = by_distance[i][1]  # берем метку (второй элемент кортежа)\n",
    "        k_nearest_labels.append(label)  # добавляем метку в список\n",
    "    \n",
    "    # Голосуем большинством\n",
    "    return majority_vote(k_nearest_labels)  # возвращаем результат голосования\n",
    "\n",
    "# Подготовка данных для KNN \n",
    "def prepare_knn_data(features, labels):\n",
    "    \"\"\"Подготавливает данные в формате (признаки, метка) для KNN\"\"\"\n",
    "    return list(zip(features, labels))  # создаем список кортежей (признаки, метка)\n",
    "\n",
    "print(\"Подготовка данных для KNN...\")\n",
    "knn_train_data = prepare_knn_data(X_train, y_train)  # готовим обучающие данные для KNN\n",
    "print(f\"Подготовлено {len(knn_train_data)} размеченных точек для KNN\")\n",
    "\n",
    "# Тестируем KNN с разными значениями k \n",
    "print(\"\\nПодбор оптимального k для KNN:\")\n",
    "best_k = 1  # лучшее значение k\n",
    "best_accuracy = 0.0  # лучшая точность\n",
    "\n",
    "for k in range(1, 8):  # пробуем k от 1 до 7\n",
    "    correct = 0  # счетчик правильных предсказаний\n",
    "    for i in range(min(100, len(X_test))):  # тестируем на первых 100 примерах для скорости\n",
    "        test_point = X_test[i]  # тестовая точка\n",
    "        true_label = y_test[i]  # истинная метка\n",
    "        \n",
    "        predicted_label = knn_classify(k, knn_train_data, test_point)  # предсказываем KNN\n",
    "        if predicted_label == true_label:  # если предсказание верное\n",
    "            correct += 1  # увеличиваем счетчик\n",
    "    \n",
    "    accuracy = correct / min(100, len(X_test))  # вычисляем точность\n",
    "    print(f\"k={k}: Точность = {accuracy:.4f} ({correct}/{min(100, len(X_test))})\")\n",
    "    \n",
    "    if accuracy > best_accuracy:  # если нашли лучшее k\n",
    "        best_accuracy = accuracy  # обновляем лучшую точность\n",
    "        best_k = k  # обновляем лучшее k\n",
    "\n",
    "print(f\"\\nОптимальное k: {best_k} с точностью {best_accuracy:.4f}\")\n",
    "\n",
    "# Предсказания KNN на всей тестовой выборке с оптимальным k\n",
    "print(\"Делаем предсказания KNN на тестовой выборке...\")\n",
    "knn_predictions = []  # список для предсказаний KNN\n",
    "for test_point in X_test:  # для каждой тестовой точки\n",
    "    predicted_label = knn_classify(best_k, knn_train_data, test_point)  # предсказываем KNN\n",
    "    knn_predictions.append(predicted_label)  # сохраняем предсказание\n",
    "\n",
    "print(\"Предсказания KNN завершены!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5caa7f6e-b8e3-4dec-8870-0046b7d77770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные разделены для тернарной классификации:\n",
      "Обучающая выборка: 644 пациентов\n",
      "Тестовая выборка: 274 пациентов\n",
      "Распределение классов в обучении: 0=152, 1=348, 2=144\n",
      "Распределение классов в тесте: 0=64, 1=149, 2=61\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных для тернарной классификации\n",
    "def split_ternary_data(features, labels, test_ratio=0.3):\n",
    "    \"\"\"Разделяет данные с тремя классами на обучающие и тестовые\"\"\"\n",
    "    \n",
    "    # Создаем списки для каждого класса\n",
    "    class_0_features = []  # список для признаков класса 0\n",
    "    class_0_labels = []    # список для меток класса 0\n",
    "    class_1_features = []  # список для признаков класса 1\n",
    "    class_1_labels = []    # список для меток класса 1\n",
    "    class_2_features = []  # список для признаков класса 2\n",
    "    class_2_labels = []    # список для меток класса 2\n",
    "    \n",
    "    # Разделяем данные по классам\n",
    "    for i in range(len(features)):  # проходим по всем данным\n",
    "        if labels[i] == 0:  # если метка класса 0\n",
    "            class_0_features.append(features[i])  # добавляем признаки в класс 0\n",
    "            class_0_labels.append(labels[i])       # добавляем метку в класс 0\n",
    "        elif labels[i] == 1:  # если метка класса 1\n",
    "            class_1_features.append(features[i])  # добавляем признаки в класс 1\n",
    "            class_1_labels.append(labels[i])       # добавляем метку в класс 1\n",
    "        else:  # если метка класса 2\n",
    "            class_2_features.append(features[i])  # добавляем признаки в класс 2\n",
    "            class_2_labels.append(labels[i])       # добавляем метку в класс 2\n",
    "    \n",
    "    # Перемешиваем каждый класс отдельно\n",
    "    random.shuffle(class_0_features)  # перемешиваем признаки класса 0\n",
    "    random.shuffle(class_1_features)  # перемешиваем признаки класса 1\n",
    "    random.shuffle(class_2_features)  # перемешиваем признаки класса 2\n",
    "    \n",
    "    # Вычисляем размеры тестовых выборок для каждого класса\n",
    "    test_size_0 = int(len(class_0_features) * test_ratio)  # 30% от класса 0\n",
    "    test_size_1 = int(len(class_1_features) * test_ratio)  # 30% от класса 1\n",
    "    test_size_2 = int(len(class_2_features) * test_ratio)  # 30% от класса 2\n",
    "    \n",
    "    # ФорМИРУЕМ ТЕСТОВУЮ ВЫБОРКУ\n",
    "    X_test_ternary = []  # список для тестовых признаков\n",
    "    y_test_ternary = []  # список для тестовых меток\n",
    "    \n",
    "    # Добавляем данные класса 0 в тестовую выборку\n",
    "    for i in range(test_size_0):  # для первых test_size_0 элементов класса 0\n",
    "        X_test_ternary.append(class_0_features[i])  # добавляем признаки в тест\n",
    "        y_test_ternary.append(class_0_labels[i])     # добавляем метки в тест\n",
    "    \n",
    "    # Добавляем данные класса 1 в тестовую выборку\n",
    "    for i in range(test_size_1):  # для первых test_size_1 элементов класса 1\n",
    "        X_test_ternary.append(class_1_features[i])  # добавляем признаки в тест\n",
    "        y_test_ternary.append(class_1_labels[i])     # добавляем метки в тест\n",
    "    \n",
    "    # Добавляем данные класса 2 в тестовую выборку\n",
    "    for i in range(test_size_2):  # для первых test_size_2 элементов класса 2\n",
    "        X_test_ternary.append(class_2_features[i])  # добавляем признаки в тест\n",
    "        y_test_ternary.append(class_2_labels[i])     # добавляем метки в тест\n",
    "    \n",
    "    # ФОРМИРУЕМ ОБУЧАЮЩУЮ ВЫБОРКУ\n",
    "    X_train_ternary = []  # список для обучающих признаков\n",
    "    y_train_ternary = []  # список для обучающих меток\n",
    "    \n",
    "    # Добавляем данные класса 0 в обучающую выборку (оставшиеся после теста)\n",
    "    for i in range(test_size_0, len(class_0_features)):  # от test_size_0 до конца\n",
    "        X_train_ternary.append(class_0_features[i])  # добавляем признаки в обучение\n",
    "        y_train_ternary.append(class_0_labels[i])     # добавляем метки в обучение\n",
    "    \n",
    "    # Добавляем данные класса 1 в обучающую выборку (оставшиеся после теста)\n",
    "    for i in range(test_size_1, len(class_1_features)):  # от test_size_1 до конца\n",
    "        X_train_ternary.append(class_1_features[i])  # добавляем признаки в обучение\n",
    "        y_train_ternary.append(class_1_labels[i])     # добавляем метки в обучение\n",
    "    \n",
    "    # Добавляем данные класса 2 в обучающую выборку (оставшиеся после теста)\n",
    "    for i in range(test_size_2, len(class_2_features)):  # от test_size_2 до конца\n",
    "        X_train_ternary.append(class_2_features[i])  # добавляем признаки в обучение\n",
    "        y_train_ternary.append(class_2_labels[i])     # добавляем метки в обучение\n",
    "    \n",
    "    # Перемешиваем обучающую выборку\n",
    "    train_combined = []  # список для объединенных данных обучения\n",
    "    for i in range(len(X_train_ternary)):  # проходим по всем обучающим данным\n",
    "        pair = (X_train_ternary[i], y_train_ternary[i])  # создаем пару (признаки, метка)\n",
    "        train_combined.append(pair)  # добавляем пару в объединенный список\n",
    "    \n",
    "    random.shuffle(train_combined)  # перемешиваем объединенные данные обучения\n",
    "    \n",
    "    # Перемешиваем тестовую выборку\n",
    "    test_combined = []  # список для объединенных данных теста\n",
    "    for i in range(len(X_test_ternary)):  # проходим по всем тестовым данным\n",
    "        pair = (X_test_ternary[i], y_test_ternary[i])  # создаем пару (признаки, метка)\n",
    "        test_combined.append(pair)  # добавляем пару в объединенный список\n",
    "    \n",
    "    random.shuffle(test_combined)  # перемешиваем объединенные данные теста\n",
    "    \n",
    "    # Разделяем объединенные данные обратно на признаки и метки\n",
    "    X_train_ternary = []  # очищаем список для обучающих признаков\n",
    "    y_train_ternary = []  # очищаем список для обучающих меток\n",
    "    \n",
    "    for item in train_combined:  # проходим по всем элементам объединенных данных обучения\n",
    "        X_train_ternary.append(item[0])  # добавляем признаки (первый элемент пары)\n",
    "        y_train_ternary.append(item[1])  # добавляем метки (второй элемент пары)\n",
    "    \n",
    "    X_test_ternary = []  # очищаем список для тестовых признаков\n",
    "    y_test_ternary = []  # очищаем список для тестовых меток\n",
    "    \n",
    "    for item in test_combined:  # проходим по всем элементам объединенных данных теста\n",
    "        X_test_ternary.append(item[0])  # добавляем признаки (первый элемент пары)\n",
    "        y_test_ternary.append(item[1])  # добавляем метки (второй элемент пары)\n",
    "    \n",
    "    return X_train_ternary, X_test_ternary, y_train_ternary, y_test_ternary\n",
    "\n",
    "# Разделяем данные для тернарной классификации\n",
    "X_train_ternary, X_test_ternary, y_train_ternary, y_test_ternary = split_ternary_data(X_ternary, y_ternary)\n",
    "\n",
    "# Выводим информацию о разделенных данных\n",
    "print(\"Данные разделены для тернарной классификации:\")\n",
    "print(f\"Обучающая выборка: {len(X_train_ternary)} пациентов\")\n",
    "print(f\"Тестовая выборка: {len(X_test_ternary)} пациентов\")\n",
    "\n",
    "# Подсчитываем распределение классов в обучающей выборке\n",
    "class_count_train = [0, 0, 0]  # счетчики для классов 0, 1, 2\n",
    "for label in y_train_ternary:  # проходим по всем меткам обучения\n",
    "    class_count_train[label] += 1  # увеличиваем счетчик соответствующего класса\n",
    "\n",
    "print(f\"Распределение классов в обучении: 0={class_count_train[0]}, 1={class_count_train[1]}, 2={class_count_train[2]}\")\n",
    "\n",
    "# Подсчитываем распределение классов в тестовой выборке\n",
    "class_count_test = [0, 0, 0]  # счетчики для классов 0, 1, 2\n",
    "for label in y_test_ternary:  # проходим по всем меткам теста\n",
    "    class_count_test[label] += 1  # увеличиваем счетчик соответствующего класса\n",
    "\n",
    "print(f\"Распределение классов в тесте: 0={class_count_test[0]}, 1={class_count_test[1]}, 2={class_count_test[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955e697-2390-4503-a391-b9238302b962",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 7: ВЫЧИСЛЕНИЕ МЕТРИК КАЧЕСТВА КЛАССИФИКАЦИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbf02947-6c15-4c92-bdcb-ad1036ec7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "МЕТРИКИ КАЧЕСТВА КЛАССИФИКАЦИИ\n",
      "============================================================\n",
      "\n",
      "--- ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (БИНАРНАЯ) ---\n",
      "Precision: 0.8364\n",
      "Recall:    0.9079\n",
      "F1-score:  0.8707\n",
      "Accuracy:  0.8509\n",
      "Матрица ошибок: TP=138, FP=27, TN=96, FN=14\n",
      "\n",
      "--- МЕТОД БЛИЖАЙШИХ СОСЕДЕЙ (БИНАРНАЯ) ---\n",
      "Precision: 0.8333\n",
      "Recall:    0.9211\n",
      "F1-score:  0.8750\n",
      "Accuracy:  0.8545\n",
      "Матрица ошибок: TP=140, FP=28, TN=95, FN=12\n",
      "\n",
      "--- ТЕРНАРНАЯ КЛАССИФИКАЦИЯ (KNN) ---\n",
      "Accuracy: 0.8212\n",
      "Распределение предсказанных классов:\n",
      "  Класс 0: 71 (25.9%)\n",
      "  Класс 1: 169 (61.7%)\n",
      "  Класс 2: 34 (12.4%)\n"
     ]
    }
   ],
   "source": [
    "# 7. Измерьте качество классификации по метрикам Precision, Recall, F1 (бинарная) и Accuracy (тернарная)\n",
    "def calculate_binary_metrics(true_labels, predicted_labels):\n",
    "    \"\"\"Вычисляет метрики для бинарной классификации\"\"\"\n",
    "    true_positives = 0  # истинные положительные\n",
    "    false_positives = 0  # ложные положительные  \n",
    "    true_negatives = 0  # истинные отрицательные\n",
    "    false_negatives = 0  # ложные отрицательные\n",
    "    \n",
    "    # Подсчет матрицы ошибок \n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        if true == 1 and pred == 1:  # TP - пациент болен и мы правильно это определили\n",
    "            true_positives += 1\n",
    "        elif true == 1 and pred == 0:  # FN - пациент болен, но мы сказали \"здоров\" \n",
    "            false_negatives += 1\n",
    "        elif true == 0 and pred == 1:  # FP - пациент здоров, но мы сказали \"болен\" \n",
    "            false_positives += 1\n",
    "        elif true == 0 and pred == 0:  # TN - пациент здоров и мы правильно это определили\n",
    "            true_negatives += 1\n",
    "    \n",
    "    # Вычисление метрик \n",
    "    # Точность: Из всех пациентов, которых мы назвали больными, сколько действительно больны?\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    # Полнота: Из всех реально больных пациентов, сколько мы правильно выявили?\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    # F1 - среднее гармоническое для точности и полноты\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    # Правильность - общая доля правильных предсказаний\n",
    "    accuracy = (true_positives + true_negatives) / len(true_labels) if len(true_labels) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall, \n",
    "        'f1': f1_score,\n",
    "        'accuracy': accuracy,\n",
    "        'tp': true_positives,\n",
    "        'fp': false_positives,\n",
    "        'tn': true_negatives,\n",
    "        'fn': false_negatives\n",
    "    }\n",
    "\n",
    "def calculate_ternary_accuracy(true_labels, predicted_labels):\n",
    "    \"\"\"Вычисляет accuracy для тернарной классификации\"\"\"\n",
    "    correct = 0  # счетчик правильных предсказаний\n",
    "    for true, pred in zip(true_labels, predicted_labels):  # для каждой пары\n",
    "        if true == pred:  # если метки совпадают\n",
    "            correct += 1  # увеличиваем счетчик\n",
    "    # Accuracy = Правильные_предсказания / Всего_предсказаний\n",
    "    return correct / len(true_labels) if len(true_labels) > 0 else 0 \n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"МЕТРИКИ КАЧЕСТВА КЛАССИФИКАЦИИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Метрики для логистической регрессии (бинарная)\n",
    "print(\"\\n--- ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (БИНАРНАЯ) ---\")\n",
    "lr_binary_metrics = calculate_binary_metrics(y_test, test_predictions_lr)\n",
    "print(f\"Precision: {lr_binary_metrics['precision']:.4f}\")\n",
    "print(f\"Recall:    {lr_binary_metrics['recall']:.4f}\") \n",
    "print(f\"F1-score:  {lr_binary_metrics['f1']:.4f}\")\n",
    "print(f\"Accuracy:  {lr_binary_metrics['accuracy']:.4f}\")\n",
    "print(f\"Матрица ошибок: TP={lr_binary_metrics['tp']}, FP={lr_binary_metrics['fp']}, TN={lr_binary_metrics['tn']}, FN={lr_binary_metrics['fn']}\")\n",
    "\n",
    "# Метрики для KNN (бинарная)\n",
    "print(\"\\n--- МЕТОД БЛИЖАЙШИХ СОСЕДЕЙ (БИНАРНАЯ) ---\")\n",
    "knn_binary_metrics = calculate_binary_metrics(y_test, knn_predictions)\n",
    "print(f\"Precision: {knn_binary_metrics['precision']:.4f}\")\n",
    "print(f\"Recall:    {knn_binary_metrics['recall']:.4f}\")\n",
    "print(f\"F1-score:  {knn_binary_metrics['f1']:.4f}\")\n",
    "print(f\"Accuracy:  {knn_binary_metrics['accuracy']:.4f}\")\n",
    "print(f\"Матрица ошибок: TP={knn_binary_metrics['tp']}, FP={knn_binary_metrics['fp']}, TN={knn_binary_metrics['tn']}, FN={knn_binary_metrics['fn']}\")\n",
    "\n",
    "# Метрики для тернарной классификации (KNN)\n",
    "print(\"\\n--- ТЕРНАРНАЯ КЛАССИФИКАЦИЯ (KNN) ---\")\n",
    "# Подготовка данных для тернарной KNN\n",
    "knn_train_ternary = prepare_knn_data(X_train_ternary, y_train_ternary)\n",
    "\n",
    "# Предсказания для тернарной классификации\n",
    "knn_ternary_predictions = []\n",
    "for test_point in X_test_ternary:\n",
    "    predicted_label = knn_classify(best_k, knn_train_ternary, test_point)\n",
    "    knn_ternary_predictions.append(predicted_label)\n",
    "\n",
    "ternary_accuracy = calculate_ternary_accuracy(y_test_ternary, knn_ternary_predictions)\n",
    "print(f\"Accuracy: {ternary_accuracy:.4f}\")\n",
    "\n",
    "# Распределение предсказаний в тернарной классификации\n",
    "ternary_distribution = {}\n",
    "for label in knn_ternary_predictions:\n",
    "    ternary_distribution[label] = ternary_distribution.get(label, 0) + 1\n",
    "\n",
    "print(\"Распределение предсказанных классов:\")\n",
    "for label, count in sorted(ternary_distribution.items()):\n",
    "    percentage = (count / len(knn_ternary_predictions)) * 100\n",
    "    print(f\"  Класс {label}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f10546-3de7-4561-85cb-bd26b0a0f41e",
   "metadata": {},
   "source": [
    "#### ЗАДАНИЕ 8: ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ И ВЫВОДЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6154bae1-59f9-4e53-aedf-3e71d55abe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ\n",
      "============================================================\n",
      "\n",
      "1. СРАВНЕНИЕ МЕТОДОВ КЛАССИФИКАЦИИ:\n",
      "   • Логистическая регрессия: Accuracy = 0.8509\n",
      "   • Метод ближайших соседей: Accuracy = 0.8545\n",
      "   ✓ Метод ближайших соседей показал лучшую точность\n",
      "\n",
      "2. АНАЛИЗ НЕСТАБИЛЬНЫХ ПРЕДСКАЗАНИЙ:\n",
      "   • Нестабильных случаев в тестовой выборке: 61 (22.3%)\n",
      "   • Эти случаи требуют дополнительного внимания врача\n",
      "\n",
      "3. КАЧЕСТВО ТЕРНАРНОЙ КЛАССИФИКАЦИИ:\n",
      "   • Accuracy тернарной классификации: 0.8212\n",
      "   • Тернарная классификация позволяет выделить 'сомнительные' случаи\n",
      "\n",
      "4. ВЫВОДЫ:\n",
      "   • Оба метода демонстрируют хорошее качество классификации\n",
      "   • Логистическая регрессия более интерпретируема (можно анализировать веса)\n",
      "   • KNN не требует обучения, но медленнее на этапе предсказания\n",
      "   • Введение третьего класса повышает надежность медицинской системы\n",
      "   • Для критических решений важна не только точность, но и возможность\n",
      "     выделения случаев, требующих дополнительной проверки\n"
     ]
    }
   ],
   "source": [
    "# 8. Интерпретация результатов - выводы о качестве классификации\n",
    "print(\"=\" * 60)\n",
    "print(\"ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. СРАВНЕНИЕ МЕТОДОВ КЛАССИФИКАЦИИ:\")\n",
    "print(f\"   • Логистическая регрессия: Accuracy = {lr_binary_metrics['accuracy']:.4f}\")\n",
    "print(f\"   • Метод ближайших соседей: Accuracy = {knn_binary_metrics['accuracy']:.4f}\")\n",
    "\n",
    "if lr_binary_metrics['accuracy'] > knn_binary_metrics['accuracy']:\n",
    "    print(\"   ✓ Логистическая регрессия показала лучшую точность\")\n",
    "elif knn_binary_metrics['accuracy'] > lr_binary_metrics['accuracy']:\n",
    "    print(\"   ✓ Метод ближайших соседей показал лучшую точность\")\n",
    "else:\n",
    "    print(\"   ○ Оба метода показали одинаковую точность\")\n",
    "\n",
    "print(\"\\n2. АНАЛИЗ НЕСТАБИЛЬНЫХ ПРЕДСКАЗАНИЙ:\")\n",
    "unstable_count = sum(1 for label in y_test_ternary if label == 2)\n",
    "unstable_percentage = (unstable_count / len(y_test_ternary)) * 100\n",
    "print(f\"   • Нестабильных случаев в тестовой выборке: {unstable_count} ({unstable_percentage:.1f}%)\")\n",
    "print(\"   • Эти случаи требуют дополнительного внимания врача\")\n",
    "\n",
    "print(\"\\n3. КАЧЕСТВО ТЕРНАРНОЙ КЛАССИФИКАЦИИ:\")\n",
    "print(f\"   • Accuracy тернарной классификации: {ternary_accuracy:.4f}\")\n",
    "print(\"   • Тернарная классификация позволяет выделить 'сомнительные' случаи\")\n",
    "\n",
    "print(\"\\n4. ВЫВОДЫ:\")\n",
    "print(\"   • Оба метода демонстрируют хорошее качество классификации\")\n",
    "print(\"   • Логистическая регрессия более интерпретируема (можно анализировать веса)\")\n",
    "print(\"   • KNN не требует обучения, но медленнее на этапе предсказания\")\n",
    "print(\"   • Введение третьего класса повышает надежность медицинской системы\")\n",
    "print(\"   • Для критических решений важна не только точность, но и возможность\")\n",
    "print(\"     выделения случаев, требующих дополнительной проверки\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
